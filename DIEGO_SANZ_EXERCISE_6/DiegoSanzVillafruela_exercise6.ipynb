{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-signal data exercise\n",
    "\n",
    "In this exercise you take on the role of a senior data analyst correcting mistakes made by a junior analyst. Your consulting company has received the MysteryData data set, and your goal is to build a classifier out of it, and evaluate how well the classifer works. You assigned the job to junior trainee Tux the Linux Penguin (who works for food).\n",
    "\n",
    "Tux is very excited to work on the data and has produced very promising results. What Tux does not yet know is that MysteryData is actually just random non-signal data where the features x and the class label y are independent of each other - it is not possible to learn anything meaningful from this data. Tux has never taken any of the UTU data analytics courses and has not noticed this. You should help Tux to correct the analyses, so you do not end up reporting incorrect results to your customers.\n",
    "\n",
    "You will write your answers inside this notebook. If all your answers are correct, your explanations thorough, and you solve the bonus questions, you will get a bonus point. Use written text, code, printouts or visualizations in you answers as needed. Return both this notebook filled (rename it lastname_firstname_studentid.ipynb), as well as a pdf export of the same notebook (same naming, but .pdf instead).\n",
    "\n",
    "The analysed problem is a binary classification task. We will follow the convention of using +1 to represent the positive class, and -1 the negative. In all but one task we will use area under ROC curve (AUC) to evaluate how well the classifier predicts. For binary classification tasks AUC and c-index are equivalent, 0.5 means random performance and 1.0 perfect predictions. The \"true\" AUC you would expect to see on a large enough sample of independent test data for any classifier trained on non-signal data is 0.5.\n",
    "\n",
    "Note that amount of samples, features, and class distribution for MysteryData can differ in different parts of the exercise (these are always written in comments above the code generating the data). Also, in one case there will be a data set on which it is possible to learn better than random classifier.\n",
    "\n",
    "Some notes on the codes:\n",
    "- we use predict_proba() instead of predict() when using AUC, because the predicted class probabilities are needed for computing AUC properly (predict() returns only +1/-1 values)\n",
    "- random seeds are fixed to guarantee that re-running the codes gives same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "#The data, trust me, you can't learn anything useful from this\n",
    "def load_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of features\n",
    "    #positives: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X = rand_state.randn(samples, features)\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    y = rand_state.permutation(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_chart(X, ref, num_bins = 20):\n",
    "    hist, bins = np.histogram(permutation_AUCs, bins=num_bins)\n",
    "    n, bins, patches = plt.hist(X, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.plot([ref, ref],[0, max(hist)], color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: some elementary mistakes\n",
    "\n",
    "## Lesson 1.1: never trust your ----- set performance\n",
    "\n",
    "The first analysis done by Tux contains an obvious elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got area under ROC curve 0.885600\n",
      "Tux: \"I got very high AUC, problem solved!!\"\n"
     ]
    }
   ],
   "source": [
    "#100 samples, 100 features, 50 belong to positive class\n",
    "X, y = load_mystery_data(100, 100, 50, 2)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "learner = KNeighborsClassifier(n_neighbors=2)\n",
    "learner.fit(X, y)\n",
    "#get the estimated probability of belonging to class 1\n",
    "p = learner.predict_proba(X)[:,1]\n",
    "auc = roc_auc_score(y, p)\n",
    "print(\"I got area under ROC curve %f\" % auc)\n",
    "print('Tux: \"I got very high AUC, problem solved!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "Why can't you trust the AUC result of Tux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer:\n",
    "\n",
    "It is not a good practice to use the same training data as test data. \n",
    "\n",
    "It is like doing an exam that you already know the answers. The teacher would have the impression that students have learnt a lot, but in reality, they did not learn anything.\n",
    "\n",
    "If the test data is the same as the training data, a high validation result is obtained but this value does not reflect the prediction performance of the model because it is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1.2: trivial baselines\n",
    "\n",
    "The second analysis done by Tux is done a bit better, but analysis of results contains another elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.900000\n",
      "Tux: \"I got 90% classification accuracy, problem solved!!\"\"\n"
     ]
    }
   ],
   "source": [
    "#1000 samples, 100 features, 100 belong to positive class\n",
    "X, y = load_mystery_data(1000, 100, 100, 1)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Instead of AUC I will use classification accuracy!\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Now I use a separate test set!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify=y, random_state=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "p_test = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, p_test)\n",
    "print(\"Classification accuracy: %f\" %accuracy)\n",
    "print('Tux: \"I got 90% classification accuracy, problem solved!!\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "1. Does the high classification accuracy really mean that this is a good predictor?\n",
    "2. Look at the test set predictions in p_test, what has this classifier actually learned?\n",
    "3. What would the results look like if you used AUC instead of classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer:\n",
    "\n",
    "1. The problem is how to interpret high classification accuracy with imbalanced classes. If 90% of examples belong to one class, predicting that class will give you trivially 90% accuracy.\n",
    "2. The test predictions in p_test are always negative (-1). The classifier only learned to classify everything as negative\n",
    "3. AUC actually close but not quite equal to 0.5 - remember, AUC is properly computed from the real-valued predictions given by predict_proba(), not the discrete predictions returned by predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: introduction to permutation tests\n",
    "\n",
    "Next, we are using permutation tests to estimate, how likely we are to see AUC values as high as observed, if y is independent of x (non-signal data).\n",
    "\n",
    "The test is implemented as follows:\n",
    "- let AUC_original be the AUC obtained in the original analysis\n",
    "- For 1000 (or preferably more if you have enough CPU time to use) repetitions, shuffle the labels in y, then run the analysis again and compute the AUC value. Store all 1000 AUC values in a list.\n",
    "- Visualization: visualize the permutation distribution by plotting a histogram of the 1000 AUC values. Does AUC_original look like an outlier, or do you often get as good or better results with permuted class labels?\n",
    "- p-value: relative fraction of runs, where obtained AUC $\\geq$ AUC_original\n",
    "- example: AUC with original class labeling is 0.6. In 70 runs out of 1000, we obtain as high as or larger AUC. p-value is then $\\frac{70}{1000} = 0.07$ \n",
    "- result is considered statistically significant, if $p<\\alpha$, where $\\alpha$ a pre-specified significance level (often $\\alpha=0.05$ or $\\alpha=0.01$). Statistical significance does not mean that the results are good, only that the classifier has likely learned something from the data. In the following experiments, use $\\alpha=0.05$.\n",
    "\n",
    "## Lesson 2.1: sample size\n",
    "\n",
    "Tux is now analyzing a small data set with 5-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.700000\n",
      "Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %auc)\n",
    "print('Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_value:  0.106\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218a5454cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref = 0.7\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "permutation_AUCs = []\n",
    "for p in range(1000):\n",
    "    # permutate class labels\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    ###\n",
    "\n",
    "   \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    auc = np.mean(cv_aucs)\n",
    "    permutation_AUCs.append(auc)\n",
    "\n",
    "permutation_AUCs = np.array(permutation_AUCs)\n",
    "better_permutation_AUCs = permutation_AUCs[permutation_AUCs >= ref]\n",
    "p = better_permutation_AUCs.size / permutation_AUCs.size\n",
    "print(\"P_value: \", p)\n",
    "\n",
    "\n",
    "visualize_chart(permutation_AUCs, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer\n",
    "The value is not statistically significant because the p_value is bigger than $\\alpha=0.05$ and we can conclude that the model has not learned anything from the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2.2: sample size again\n",
    "\n",
    "Let's give poor Tux a better data set that actually has clear difference between the classes and see how things work out. (on this data it is possible to obtain true AUC larger than 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_new_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X_pos = rand_state.randn(positives, features)\n",
    "    X_neg = rand_state.randn(samples-positives, features)+0.65\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    I = rand_state.permutation(samples)\n",
    "    X = X[I]\n",
    "    y = y[I]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.875000\n",
      "Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_new_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %cv_auc)\n",
    "print('Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_value:  0.003\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBU4D6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218a544a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref = 0.875000\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_new_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "permutation_AUCs = []\n",
    "for p in range(1000):\n",
    "    # permutate class labels\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    # CV\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    auc = np.mean(cv_aucs)\n",
    "    # End CV\n",
    "    permutation_AUCs.append(auc)\n",
    "    \n",
    "permutation_AUCs = np.array(permutation_AUCs)\n",
    "better_permutation_AUCs = permutation_AUCs[permutation_AUCs >= ref]\n",
    "p = better_permutation_AUCs.size / permutation_AUCs.size\n",
    "print(\"P_value: \", p)\n",
    "\n",
    "visualize_chart(permutation_AUCs, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer\n",
    "The value is statistically significant because the p_value is lower than $\\alpha=0.05$ and we can conclude that the model has learned from the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: mis-using feature selection\n",
    "\n",
    "Here is a very simple correlation based feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return X[:,I[:scount]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tux: \"My CV-AUC before feature selection is 0.496000\"\n",
      "Tux: \"My CV-AUC after feature selection is 0.808000, it really works!!\"\n"
     ]
    }
   ],
   "source": [
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC before feature selection is %f\"' %cv_auc)\n",
    "\n",
    "\n",
    "#I'm going to improve my AUC with feature selection!!!\n",
    "X_fs = select(X, y, 5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X_fs, y):\n",
    "    X_train = X_fs[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X_fs[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC after feature selection is %f, it really works!!\"' %cv_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "\n",
    "Use permutation test to show Tux that the feature selection based classification approach is actually not learning anything from the data ($\\alpha=0.05$, provide both visualization of the permutation distribution, as well as the p-value). Running the test may take a while. Analyse what is going on here, why did the results look so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_value:  0.672\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218a50726a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref = 0.808000\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "permutation_AUCs = []\n",
    "for i in range(1000):\n",
    "    # permutate class labels\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    # bad feature selection\n",
    "    \n",
    "    #I'm going to improve my AUC with feature selection!!!\n",
    "    X_fs = select(X, y, 5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X_fs, y):\n",
    "        X_train = X_fs[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X_fs[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    cv_auc = np.mean(cv_aucs)\n",
    "    \n",
    "    # End\n",
    "    permutation_AUCs.append(cv_auc)\n",
    "    \n",
    "permutation_AUCs = np.array(permutation_AUCs)\n",
    "better_permutation_AUCs = permutation_AUCs[permutation_AUCs >= ref]\n",
    "p = better_permutation_AUCs.size / permutation_AUCs.size\n",
    "print(\"P_value: \", p)\n",
    "\n",
    "\n",
    "visualize_chart(permutation_AUCs, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer\n",
    "The value is not statistically significant because the p_value is bigger than $\\alpha=0.05$ and we can conclude that the model has not learned anything from the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 (bonus exercise)\n",
    "\n",
    "Correct the bias in above example by combining feature selection properly with cross-validation, run the experiment again. Do also a permutation test for this experiment with as many permutations as you can afford in a reasonable amount of time.\n",
    "\n",
    "Q 3.2. Bonus question is not solved correctly - in the correct solution you would select the features only on the training folds, not all folds. If done correctly, the AUC values would fall close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tux: \"My CV-AUC after feature selection is 0.808000, it really works!!\"\n"
     ]
    }
   ],
   "source": [
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def select_indexes(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return I[:scount]\n",
    "\n",
    "\n",
    "#I'm going to improve my AUC with feature selection!!!\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "\n",
    "    #I'm going to improve my AUC with feature selection!!!\n",
    "    I = select_indexes(X_train, y, 5) # feature indexes\n",
    "    \n",
    "    # filtered by selected features\n",
    "    X_fs_train = X_train[:, I]\n",
    "    \n",
    "    y_train = y[train]\n",
    "\n",
    "    # filtered by test and selected features\n",
    "    X_test = X[test]\n",
    "    X_fs_test = X_test[:, I]\n",
    "    \n",
    "    y_test = y[test]\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_fs_train, y_train)\n",
    "    p_test = knn.predict_proba(X_fs_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC after feature selection is %f, it really works!!\"' %cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_value:  0.6646666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218a546f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "ref = 0.808000\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "permutation_AUCs = []\n",
    "for p in range(3000):\n",
    "    # permutate class labels\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    # good feature selection\n",
    "    \n",
    "    #I'm going to improve my AUC with feature selection!!!\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "\n",
    "        X_train = X[train]\n",
    "\n",
    "        #I'm going to improve my AUC with feature selection!!!\n",
    "        I = select_indexes(X_train, y, 5) # feature indexes\n",
    "\n",
    "        # filtered by selected features\n",
    "        X_fs_train = X_train[:, I]\n",
    "\n",
    "        y_train = y[train]\n",
    "\n",
    "        # filtered by test and selected features\n",
    "        X_test = X[test]\n",
    "        X_fs_test = X_test[:, I]\n",
    "\n",
    "        y_test = y[test]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_fs_train, y_train)\n",
    "        p_test = knn.predict_proba(X_fs_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    # End\n",
    "    \n",
    "    cv_auc = np.mean(cv_aucs)\n",
    "\n",
    "    permutation_AUCs.append(cv_auc)\n",
    "    \n",
    "permutation_AUCs = np.array(permutation_AUCs)\n",
    "better_permutation_AUCs = permutation_AUCs[permutation_AUCs >= ref]\n",
    "p = better_permutation_AUCs.size / permutation_AUCs.size\n",
    "print(\"P_value: \", p)\n",
    "\n",
    "\n",
    "visualize_chart(permutation_AUCs, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### answer\n",
    "\n",
    "The value is not statistically significant because the p_value is bigger than $\\alpha=0.05$ and we can conclude that the model has not learned anything from the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
