{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Cross-Validation with Symmetric Pair-Input Data\n",
    "\n",
    "This exercise consists of two tasks. The first task is compulsory: you will not get the right to take the exam if you fail the first task. The second task optional: you do not have to complete the second task but a successful completion will give you an extra point in the exam.\n",
    "\n",
    "In both tasks, use the K-nearest neighbors classifier with K=1 and Euclidean distance for learning and the concordance index for evaluation. You are encouraged to re-use your own code from the previous exercises. Use the data files `pairs.data`, `features.data`, and `labels.data` that are available in Moodle. The descriptions of these files are provided in the exercise overview, which is also available in Moodle.\n",
    "\n",
    "Follow the general exercise guidelines of the course (listed in Moodle). Particularly,\n",
    "\n",
    "- Describe and implement your solution directly to this Jupyter notebook file.\n",
    "- Remember to describe your solution in general and add detailed comments to the critical parts of your code.\n",
    "- Remember to justify your design choices and discuss your results.\n",
    "- Your report must be easy to follow and your code must be runnable in Jupyter notebook.\n",
    "\n",
    "Feel free to use markdown cells and code cells as you see appropriate.\n",
    "\n",
    "Submit the finished work to Moodle before the **deadline Monday 18th of February 2019 at 23:59**. Late submissions will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIEGO SANZ VILLAFRUELA\n",
    "\n",
    "518736"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (compulsory)\n",
    "\n",
    "**You must successfully complete this task in order to get the right to take the exam.**\n",
    "\n",
    "1. Implement the modified leave-one-out cross-validation scheme that is described in the lecture notes.\n",
    "\n",
    "2. Estimate and report the generalisation performance of the K-nearest neighbor classifier in predicting the functional similarity of proteins. Use both the unmodified and the modified leave-one-out cross-validation.\n",
    "\n",
    "3. Discuss your results. In particular, answer the following questions:\n",
    " - Why do the two cross-validation schemes produce notably different estimates?\n",
    " - Which scheme is appropriate for estimating the generalisation performance on which types of pairs (A, B, or C) and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gets samples from CSV file.\n",
    "\"\"\"                \n",
    "def getSamples(filename, delimiter):\n",
    "    samples = []\n",
    "    with open(filename) as f:\n",
    "        linesIter = iter(f.readlines())\n",
    "\n",
    "        for line in linesIter:\n",
    "            line = line.rstrip(\"\\n\\r\")\n",
    "            sample = []\n",
    "            for value in line.split(delimiter):\n",
    "                sample.append(int(value.upper().replace(\"P\",\"\"))) \n",
    "            samples.append(sample)\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performance measure that indicates how well the model captures the relative ordering/ranking\n",
    "of the data points.\n",
    "C-index is measured from 0 to 1, with 0.5 meaning the model wasn't able to capture any information\n",
    "from the data.\n",
    "\"\"\"\n",
    "def getCIndex(labels, predictions):\n",
    "    if labels is None or predictions is None:\n",
    "        raise Exception(\"Illegal argument exception\")\n",
    "    if len(labels) != len(predictions):\n",
    "        raise Exception(\"The number of labels is not the same to the number of predictions\")\n",
    "        \n",
    "    size = len(labels)\n",
    "    h_num = 0\n",
    "    n = 0\n",
    "    for i in range(size):\n",
    "        li = labels[i]\n",
    "        pi = predictions[i]\n",
    "        for j in range(i+1,size):\n",
    "            lj = labels[j]\n",
    "            pj = predictions[j]\n",
    "            if ( li != lj):\n",
    "                n += 1\n",
    "                if (pi < pj and li < lj) or (pi > pj and li > lj):\n",
    "                    h_num += 1\n",
    "                elif pi == pj:\n",
    "                    h_num += 0.5 # -1 0.5 1\n",
    "    return h_num/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates the Ecludean distance between 2 samples. \n",
    "It is mainly used when data is continuous.\n",
    "Note:\n",
    "Discrete data can only take particular values whereas Continuous data are not restricted\n",
    "to defined separate values, but can occupy any value over a continuous range.\n",
    "\"\"\"\n",
    "def euclideanDistance(instance1, instance2, origin, end):\n",
    "    distance = 0\n",
    "    for propertyIndex in range(origin, end):\n",
    "        distance += pow((instance1[propertyIndex] - instance2[propertyIndex]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\"\"\"\n",
    "Gets the k closest neighbors from the trainingSet. \n",
    "\"\"\"\n",
    "def getNeighbors(trainingSet, testInstance, k, dead_radius, origin_property, end_property):\n",
    "    distances = []\n",
    "    \n",
    "    for train_element in trainingSet:\n",
    "        euclidean_dist = euclideanDistance(testInstance, train_element, origin_property, end_property)\n",
    "        distances.append((euclidean_dist, train_element))\n",
    "           \n",
    "    distances.sort(key=operator.itemgetter(0))\n",
    "   \n",
    "    best_neighbors = []\n",
    "    n = min(k, len(distances))\n",
    "    for i in range(n):\n",
    "        best_neighbors.append(distances[i][1])\n",
    "    \n",
    "    return best_neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    length = len(neighbors)\n",
    "    if length == 0:\n",
    "        raise ValueError(\"The number of elements is 0\")\n",
    "    \n",
    "    prediction = 0\n",
    "    for neighbor in neighbors:\n",
    "        prediction += neighbor[-1]\n",
    "    \n",
    "    return prediction / len(neighbors)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Calculates the accuracy of a kNearestNeighbors classifier.\n",
    "\"\"\"\n",
    "def kNearestNeighbors(trainingData, testData, **kwargs):\n",
    "    k = kwargs.get(\"k\")\n",
    "    dead_radius = kwargs.get(\"radius\")\n",
    "    origin_property = kwargs.get(\"origin_property\")\n",
    "    end_property = kwargs.get(\"end_property\")\n",
    "    \n",
    "    if k is None:\n",
    "        k = 1\n",
    "    \n",
    "    if origin_property is None or end_property is None:\n",
    "        raise ValueError(\"You didn't specify the input properties\")\n",
    "        \n",
    "    if k > len(trainingData):\n",
    "        raise ValueError(\"Elements are less than k: {}\".format(k))\n",
    "    \n",
    "    if testData.ndim != 2:\n",
    "        raise ValueError(\"TesData must have dimension 2 and not {}\".format(testData.ndim))\n",
    "\n",
    "    if trainingData.ndim != 2:\n",
    "        raise ValueError(\"TrainingData must have dimension 2 and not {}\".format(trainingData.ndim))\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for testInstance in testData:\n",
    "    \n",
    "        neighbors = getNeighbors(trainingData, testInstance, k, dead_radius, origin_property, end_property)\n",
    "        \n",
    "        prediction = getResponse(neighbors)\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_filtered_pairs(instances, test_instance, end_property):\n",
    "    result = []\n",
    "    \n",
    "    first_test_element = test_instance[end_property]\n",
    "    second_test_element = test_instance[end_property + 1]\n",
    "    \n",
    "    for instance in instances:\n",
    "        first_train_element = instance[end_property]\n",
    "        second_train_element = instance[end_property + 1]\n",
    "        \n",
    "        if first_train_element != first_test_element and second_train_element != first_test_element and first_train_element != second_test_element and second_train_element != second_test_element :\n",
    "            result.append(instance)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def leave_one_out_cv(samples, end, filter_pairs_active, predictionMethod, **kwargs):\n",
    "    n = len(samples[0])\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for fold in range(0,len(samples)):\n",
    "        testData =  samples[fold]\n",
    "        \n",
    "        # elements outside the dead zone\n",
    "        if filter_pairs_active:\n",
    "            trainingData = get_filtered_pairs(samples[:fold], testData, end) \\\n",
    "                        + get_filtered_pairs(samples[fold+1:], testData, end)\n",
    "        else:\n",
    "            trainingData = np.concatenate((samples[:fold],samples[fold+1:]), axis=0)\n",
    "                \n",
    "        trainingData = np.array(trainingData)\n",
    "        # testada must have dimension 2 before being pass to knn\n",
    "        testData = testData.reshape((1,n))\n",
    "            \n",
    "        # -----------------------------------------\n",
    "        # predictions\n",
    "        predictions = predictionMethod(trainingData, testData, **kwargs)\n",
    "        labels = [testInstance[-1] for testInstance in testData]\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels)\n",
    "        #print(\"Fold:{}, k:{} , len(trainingData:{} , dead_radius:{}\".format(fold, k, len(trainingData), dead_radius))\n",
    "        \n",
    "    return getCIndex(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified leave-one-out cross-validation C-index: 0.6313559322033898\n",
      "Unmodified leave-one-out cross-validation C-index: 0.7617702448210922\n"
     ]
    }
   ],
   "source": [
    "# READING THE DATA\n",
    "INPUT_DATA = getSamples('features.data', delimiter=',')\n",
    "PAIRS_DATA = getSamples('pairs.data', delimiter=',') # np.genfromtxt\n",
    "OUTPUT_DATA = getSamples('labels.data', delimiter=',')\n",
    "OUTPUT_DATA = OUTPUT_DATA.reshape((len(OUTPUT_DATA), 1))\n",
    "\n",
    "ALL_DATA = np.concatenate((INPUT_DATA, PAIRS_DATA, OUTPUT_DATA), axis=1)\n",
    "\n",
    "k = 1\n",
    "dead_radius = 1\n",
    "\n",
    "realistic_index = leave_one_out_cv(ALL_DATA, len(INPUT_DATA[0]), True, kNearestNeighbors, k=k, origin_property=0, end_property=len(INPUT_DATA[0]))\n",
    "optimistic_index = leave_one_out_cv(ALL_DATA, len(INPUT_DATA[0]), False, kNearestNeighbors, k=k, origin_property=0, end_property=len(INPUT_DATA[0]))\n",
    "\n",
    "print(\"Modified leave-one-out cross-validation C-index:\", realistic_index)\n",
    "print(\"Unmodified leave-one-out cross-validation C-index:\", optimistic_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do the two cross-validation schemes produce notably different estimates?\n",
    "\n",
    "The modified leave-one-out cross-validation gets worse results than the Unmodified leave-one-out cross-validation, 0.6313559322033898 vs 0.7617702448210922.\n",
    "\n",
    "The reason why in the unmodified leave-one-out cross-validation better obtains better results is that there are dependencies between the training data and the test data, getting optimistic results.\n",
    "\n",
    "On the other hand, the Unmodified leave-one-out cross-validation gets worse results is because the correlated pair of proteins are eliminated from the train data if they are part of the test data. \n",
    "\n",
    "## Which scheme is appropriate for estimating the generalisation performance on which types of pairs (A, B, or C) and why?\n",
    "\n",
    "The appropriate scheme for estimating the generalisation performance is the modified leave-one-out cross-validation.\n",
    "\n",
    "As I mentioned above, modified leave-one-out cross-validation eliminates the dependencies between the training data and the test data, making the validation of the model more realistic to the nature of the problem, although lower validation performance(c-index) is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (optional)\n",
    "\n",
    "**Successfully completing this task will give you an extra point in the exam.**\n",
    "\n",
    "1. Design a leave-one-out cross-validation scheme that is appropriate for estimating the generalisation performance on the type of pairs for which the two aforementioned schemes are not appropriate.\n",
    "\n",
    "2. Explain why your cross-validation scheme is appropriate.\n",
    "\n",
    "3. Implement your cross-validation scheme. Estimate and report the generalisation performance as in the first task.\n",
    "\n",
    "4. Discuss your results. In particular, compare the results to those you obtained in the first task and give reasons for any similarities or differences you observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[write your answer to task 2 here]*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
